---
title: "TFG: Estudio de oncogenes en muestras tumorales a través de técnicas de Machine Learning"
author: Realizado por Miguel Ángel haro Jiménez
output:
  html_document:
    df_print: paged
    toc: true
    toc_depth: 5  
    number_sections: true
    toc_float:
      collapsed: true    
      smooth_scroll: true
  pdf_document: default
---

# Construcción de los datos

## Carga de datos

Carga de las librerías y de los datos necesarios para llevar a cabo el estudio.

```{r}
# install.packages("conflicted")
# install.packages("caret")
# install.packages("purrr")
# install.packages("ggplot2")
# install.packages("lattice")
# install.packages("randomForest")
# install.packages("gridExtra")
# install.packages("e1071")
# install.packages("kernlab")
# install.packages("Rtsne")
# install.packages("openxlsx")
# install.packages("magrittr")
# install.packages("dplyr")
# install.packages("tidyverse")
# install.packages("DALEX")
# install.packages("nnet")
# install.packages("moments")
# install.packages("umap")
# install.packages("rpart")
# install.packages("rpart.plot")
# install.packages("nnet")


library(conflicted)
library(caret)
library(purrr)
library(ggplot2)
library(lattice)
library(randomForest)
library(gridExtra)
library(e1071)
library(kernlab)
library(Rtsne)
library(openxlsx)
library(magrittr)
library(dplyr)
library(tidyverse)
library(DALEX)
library(nnet)
library(moments)
library(umap)
library(rpart)
library(rpart.plot)
library(nnet)

# Resolver conflictos con conflicted
conflict_prefer("filter", "dplyr")
conflict_prefer("lag", "dplyr")
conflict_prefer("combine", "dplyr")
conflict_prefer("alpha", "ggplot2")
conflict_prefer("cross", "purrr")
conflict_prefer("set_names", "purrr")
conflict_prefer("lift", "caret")
conflict_prefer("margin", "randomForest")


#Carga de datasets
#tejido sano de próstata
normal_A=read.table('data/prostate-rsem-fpkm-gtex.txt.gz',header = T) 
#tejido sano de pulmones
normal_B=read.table('data/lung-rsem-fpkm-gtex.txt.gz',header = T) 

#adenocarcinoma de próstata
tumor_A=read.table('data/prad-rsem-fpkm-tcga-t.txt.gz',header = T)
#adenocarcinoma de pulmones
tumor_B=read.table('data/luad-rsem-fpkm-tcga-t.txt.gz',header = T) 
```

**Visualización previa de los datos.**

```{r}
print(tumor_A[1:5, 1:4])
```

Podemos observar que las dos primeras columnas se corresponden al **nombre** y el **ID** del gen. Las demás se corresponen con identificadores de las distintas **muestras** obtenidas.

Para reducir la dimensionalidad de los datos, vamos a realizar un filtrado de los genes, quedándonos solo con aquellos que están comprobados que son oncogenes.

```{r}
#carga de oncogenes
cancer_genes = read.delim('data/NCG6_tsgoncogene.tsv',header = T,sep='\t')
```

**Comprobación de la individualidad de los datos**

Se debe comprobar que no haya datos repetidos en los conjuntos de datos de los tejidos normales y tumorales.

```{r}
Hugo_Symbols<- as.data.frame(tumor_A$Hugo_Symbol) 
Hugo_Symbols_repetidos <- Hugo_Symbols %>% group_by(`tumor_A$Hugo_Symbol`) %>% summarise(cantidad = n()) %>% filter(cantidad > 1)



Genes_Id <- as.data.frame(tumor_A$Entrez_Gene_Id) 
Genes_Id_repetidos <- Genes_Id %>% group_by(`tumor_A$Entrez_Gene_Id`) %>% summarise(cantidad = n()) %>% filter(cantidad > 1)

cat("Número de Hugo Symbols repetidos", sum(Hugo_Symbols_repetidos), "\n")
cat("Número de identificadores numéricos repetidos:", sum(Genes_Id_repetidos$cantidad))

```

Tras ejecutar el chunk anterior, se observa que hay varios genes que poseen el mismo ID. Es por ello que se realiza un filtrado de estos, guardando tan solo aquellos IDs que aparecen en el archivo de los oncogenes, que son los interesantes para el objetivo de este estudio. En caso de que dos genes posean un ID presente en el archivo de oncogenes, se seleccionará aquel gen cuyo nombre también aparezca en el archivo.

## Filtrado de datos

Filtrado de los datos para seleccionar aquellos que son oncogenes y reducir la dimensionalidad del conjunto de datos.

```{r}

### DATOS TEJIDO TUMOR A

#Filtrado de Ids por aquellos presentes en el dataset cancer_genes
tumor_A <- tumor_A %>% filter(Entrez_Gene_Id %in% cancer_genes$entrez) 

#Creación de una variable, rep, que guarde todos aquellos Ids que aparezcan más de una vez en el dataset tumor_A
rep <- tumor_A %>% count(Entrez_Gene_Id) %>% filter(n > 1) %>% pull(Entrez_Gene_Id) 

#Filtrado del dataset tumor_A incluyendo aquellos genes cuyos IDs no estén presentes en rep, o en caso de estarlo, su Hugo_Symbol (nombre del gen) esté presente en el archivo de los oncogenes
tumor_A <- tumor_A %>% filter(!(Entrez_Gene_Id %in% rep) | (Hugo_Symbol %in% subset(cancer_genes, entrez %in% rep)$symbol)) 

#Por último, se cambian los índices del dataset (números identificativos de las filas) por el ID del gen de esa fila.
rownames(tumor_A)=tumor_A$Entrez_Gene_Id

#----------------------------------------------------------
  
### DATOS TEJIDO TUMOR B
  
tumor_B <- tumor_B %>%
  filter(Entrez_Gene_Id %in% cancer_genes$entrez)

rep <- tumor_B %>% count(Entrez_Gene_Id) %>% filter(n > 1) %>% pull(Entrez_Gene_Id)

tumor_B <- tumor_B %>%
  filter(!(Entrez_Gene_Id %in% rep) | (Hugo_Symbol %in% subset(cancer_genes, entrez %in% rep)$symbol))

rownames(tumor_B)=tumor_B$Entrez_Gene_Id

#----------------------------------------------------------
  
### DATOS TEJIDO NORMAL A
  
normal_A <- normal_A %>%
  filter(Entrez_Gene_Id %in% cancer_genes$entrez)

rep <- normal_A %>% count(Entrez_Gene_Id) %>% filter(n > 1) %>% pull(Entrez_Gene_Id)

normal_A <- normal_A %>%
  filter(!(Entrez_Gene_Id %in% rep) | (Hugo_Symbol %in% subset(cancer_genes, entrez %in% rep)$symbol))

rownames(normal_A)=normal_A$Entrez_Gene_Id  

#----------------------------------------------------------

  
### DATOS TEJIDO NORMAL B

normal_B <- normal_B %>%
  filter(Entrez_Gene_Id %in% cancer_genes$entrez)

rep <- normal_B %>% count(Entrez_Gene_Id) %>% filter(n > 1) %>% pull(Entrez_Gene_Id)

normal_B <- normal_B %>%
  filter(!(Entrez_Gene_Id %in% rep) | (Hugo_Symbol %in% subset(cancer_genes, entrez %in% rep)$symbol))

rownames(normal_B)=normal_B$Entrez_Gene_Id
  
```

## División de los datos en train set y test set

División del conjunto de datos en dos partes, una parte de entrenamiento (train) y otra para evaluación (test).

```{r}

#Carga de una semilla para asegurar la reproducibilidad del estudio
set.seed(900808)


# Se excluyen las dos primeras columnas del dataset tumor_A (nombres de genes e IDs de genes) 
tumor_A_data <- tumor_A[, -c(1, 2) ]

# Creación de una partición estratificada para dividir el conjunto de datos mediante el uso de la librería Caret
particionA <- createDataPartition(y = seq_len(ncol(tumor_A_data)),p = 0.75,list = FALSE)


# División de los datos en conjunto de entrenamiento y conjunto de pruebas
# Unión de las dos primeras columnas de los datasets (nombres e IDs) con las columnas de la partición
tumor_A_train <- bind_cols(select(tumor_A, 1:2), tumor_A_data[, particionA])
rownames(tumor_A_train)=tumor_A_train$Entrez_Gene_Id

tumor_A_test <- cbind(tumor_A[,1:2 ], tumor_A_data[, -particionA])
rownames(tumor_A_test)=tumor_A_test$Entrez_Gene_Id

#----------------------------------------------------------------------------------------------------------------------------
tumor_B_data <- tumor_B[, -c(1, 2) ]

particionB <- createDataPartition(y = seq_len(ncol(tumor_B_data)),p = 0.75,list = FALSE)

tumor_B_train <- bind_cols(select(tumor_B, 1:2), tumor_B_data[, particionB])
rownames(tumor_B_train)=tumor_B_train$Entrez_Gene_Id

tumor_B_test <- cbind(tumor_B[,1:2 ], tumor_B_data[, -particionB])
rownames(tumor_B_test)=tumor_B_test$Entrez_Gene_Id

#----------------------------------------------------------------------------------------------------------------------------

normal_A_data <- normal_A[, -c(1, 2) ]

particionNA <- createDataPartition(y = seq_len(ncol(normal_A_data)),p = 0.75,list = FALSE)

normal_A_train <- bind_cols(select(normal_A, 1:2), normal_A_data[, particionNA])
rownames(normal_A_train)=normal_A_train$Entrez_Gene_Id

normal_A_test <- cbind(normal_A[,1:2 ], normal_A_data[, -particionNA])
rownames(normal_A_test)=normal_A_test$Entrez_Gene_Id

#----------------------------------------------------------------------------------------------------------------------------
normal_B_data <- normal_B[, -c(1, 2) ]

particionNB <- createDataPartition(y = seq_len(ncol(normal_B_data)),p = 0.75,list = FALSE)

normal_B_train <- bind_cols(select(normal_B, 1:2), normal_B_data[, particionNB])
rownames(normal_B_train)=normal_B_train$Entrez_Gene_Id

normal_B_test <- cbind(normal_B[,1:2 ], normal_B_data[, -particionNB])
rownames(normal_B_test)=normal_B_test$Entrez_Gene_Id
```

## Creación de las matrices de train y test

A continuación se muestran comentados los pasos para la creación de las matrices usadas en la experimentación.

### Matriz de train

```{r}

# TUMOR
# Filtrar tumor_A_train escogiendo los genes que se encuentren en tumor_B_train
tumor_A_train <- tumor_A_train %>% filter(Entrez_Gene_Id %in% tumor_B_train$Entrez_Gene_Id)

#Se le ponen los IDs a los índices de las filas
rownames(tumor_A_train)=tumor_A_train$Entrez_Gene_Id

# Filtrar tumor_B_train de manera que se quede con los genes presentes en tumor_A_train
tumor_B_train <- tumor_B_train %>% filter(Entrez_Gene_Id %in% tumor_A_train$Entrez_Gene_Id)
rownames(tumor_B_train)=tumor_B_train$Entrez_Gene_Id


# SI NO PONES AS.DATA.FRAME SE TE GUARDA COMO UNA MATRIZ Y NO COMO UN DATAFRAME
#tumor_train_set2 <- (t(cbind(tumor_A_train[,3:ncol(tumor_A_train)],tumor_B_train[,3:ncol(tumor_B_train)])))
#Se unen ambos datasets de train, combinando las columnas de ambos y escogiendo todas las filas
tumor_train_set = as.data.frame(t(cbind(tumor_A_train[,3:ncol(tumor_A_train)],tumor_B_train[,3:ncol(tumor_B_train)])))


#NORMAL
normal_A_train <- normal_A_train %>% filter(Entrez_Gene_Id %in% normal_B_train$Entrez_Gene_Id)
rownames(normal_A_train)=normal_A_train$Entrez_Gene_Id

normal_B_train <- normal_B_train %>% filter(Entrez_Gene_Id %in% normal_A_train$Entrez_Gene_Id)
rownames(normal_B_train)=normal_B_train$Entrez_Gene_Id

normal_train_set = as.data.frame(t(cbind(normal_A_train[,3:ncol(normal_A_train)],normal_B_train[,3:ncol(normal_B_train)])))


#MERGE
#Comprobación de que tienen el mismo de columnas 
ncol(tumor_train_set) == ncol(normal_train_set)
sum(colnames(tumor_train_set)==colnames(normal_train_set))/ncol(normal_train_set)

#Se crea train_set uniendo las filas (muestras) tumor_train_set y normal_train_set
train_set = rbind(tumor_train_set,normal_train_set)

#Se le cambia el nombre a las columnas, añadiendo 'g_' delante del ID de cada gen
colnames(train_set)=paste0('g_',colnames(train_set)[1:(ncol(train_set))])


# Crear variable tipo factor que se corresponde con la etiqueta de la muestra 'Normal' o 'Tumor'.
factor_tipo <- factor(c(rep('Tumor', nrow(tumor_train_set)), rep('Normal', nrow(normal_train_set))), levels = c('Normal', 'Tumor'))

# Agregar la columna type al dataset test_set
train_set <- mutate(train_set, Tipo = factor_tipo)




```

### Matriz de test

Volvemos a repetir el mismo proceso que el anterior.

```{r}
#Se reproduce lo anterio,r ahora con los datos de validación (test)

# Filtrar tumor_A_train
tumor_A_test <- tumor_A_test %>% filter(Entrez_Gene_Id %in% tumor_B_test$Entrez_Gene_Id)
rownames(tumor_A_test)=tumor_A_test$Entrez_Gene_Id

tumor_B_test <- tumor_B_test %>% filter(Entrez_Gene_Id %in% tumor_A_test$Entrez_Gene_Id)
rownames(tumor_B_test)=tumor_B_test$Entrez_Gene_Id


# SI NO PONES AS.DATA.FRAME SE TE GUARDA COMO UNA MATRIZ Y NO COMO UN DATAFRAME
#tumor_train_set2 <- (t(cbind(tumor_A_train[,3:ncol(tumor_A_train)],tumor_B_train[,3:ncol(tumor_B_train)])))
tumor_test_set = as.data.frame(t(cbind(tumor_A_test[,3:ncol(tumor_A_test)],tumor_B_test[,3:ncol(tumor_B_test)])))


normal_A_test <- normal_A_test %>% filter(Entrez_Gene_Id %in% normal_B_test$Entrez_Gene_Id)
rownames(normal_A_test)=normal_A_test$Entrez_Gene_Id

normal_B_test <- normal_B_test %>% filter(Entrez_Gene_Id %in% normal_A_test$Entrez_Gene_Id)
rownames(normal_B_test)=normal_B_test$Entrez_Gene_Id

normal_test_set = as.data.frame(t(cbind(normal_A_test[,3:ncol(normal_A_test)],normal_B_test[,3:ncol(normal_B_test)])))


ncol(tumor_test_set) == ncol(normal_test_set)
sum(colnames(tumor_test_set)==colnames(normal_test_set))/ncol(normal_test_set)

test_set = rbind(tumor_test_set,normal_test_set)

colnames(test_set)=paste0('g_',colnames(test_set)[1:(ncol(test_set))])

# Crear el factor para la columna type
factor_tipo <- factor(c(rep('Tumor', nrow(tumor_test_set)), rep('Normal', nrow(normal_test_set))), levels = c('Normal', 'Tumor'))

# Agregar la columna type al dataset test_set
test_set <- mutate(test_set, Tipo = factor_tipo)

```

## Proporción de las muestras

### Proporción en test_set

```{r}
table(test_set$Tipo)

prop.table(table(test_set$Tipo)) %>% round(digits = 2)
```

```{r}
ggplot(data = test_set, aes(x = Tipo, y = after_stat(count), fill = Tipo)) +
  geom_bar() +
  scale_fill_manual(values = c("blue3", "cyan4")) +
  labs(title = "Tipo") +
  theme_bw() +
  theme(legend.position = "bottom")
```

### Proporción en train_set

```{r}
table(train_set$Tipo)

prop.table(table(train_set$Tipo)) %>% round(digits = 2)
```

```{r}
ggplot(data = train_set, aes(x = Tipo, y = after_stat(count), fill = Tipo)) +
  geom_bar() +
  scale_fill_manual(values = c("blue3", "cyan4")) +
  labs(title = "Tipo") +
  theme_bw() +
  theme(legend.position = "bottom")
```

### Unión de las matrices train y test

En primer lugar, vamos a crear una nueva variable que combine ambas matrices para posteriormente, realizar una serie de transformaciones.

```{r}
#Combinar los dos conjuntos de datos creados anterirormente: train_set y test_set
tmp = rbind(train_set,test_set)

#Eliminación de la última variable 'Tipo' para más adelante
all_data = tmp[,1:(ncol(tmp)-1)]
```

### Proporción en tmp

```{r}
table(tmp$Tipo)
prop.table(table(tmp$Tipo)) %>% round(digits = 2)
```

```{r}
ggplot(data = tmp, aes(x = Tipo, y = after_stat(count), fill = Tipo)) +
  geom_bar() +
  scale_fill_manual(values = c("blue3", "cyan4")) +
  labs(title = "Tipo") +
  theme_bw() +
  theme(legend.position = "bottom")
```

## Pre-procesamiento

### Visualización de la distribución normal de los datos

```{r}
par(mfrow = c(1, 4))  # Divide la ventana gráfica en 1 fila y 3 columnas

for (i in 1:50) {
  qqnorm(all_data[, i], main = paste("QQ-plot de la columna", i))
  qqline(all_data[, i])
}
```

Como se observa en las gráficas, los datos no se adaptan a una distribución normal. Es por ello que será necesario tratarlos.

### Identificación de valores perdidos

```{r}
# Comprobar si hay datos incompletos

filas_totales <- nrow(all_data)
filas_completas <- nrow(na.omit(all_data))

cat("Número total de filas:", filas_totales, "\n")
cat("Número de filas completas (sin valores perdidos):", filas_completas, "\n")

if (filas_totales == filas_completas) {
  cat("No hay valores perdidos en el dataset.\n")
} else {
  cat("Hay valores perdidos en el dataset.\n")
}

```

### Comprobación de la varianza

Comprobación de la varianza de los genes, ya que si esta es 0 o cercana, significa que esos genes no se expresan y no son importantes para el estudio.

```{r}
calcular_varianza <- function(data) {
  varianzas <- apply(data, 2, var)  # Calcula la varianza de cada columna
  varianzas_cercanas_a_cero <- varianzas[varianzas <= 0.001]  # Filtra las varianzas cercanas a 0
  if (length(varianzas_cercanas_a_cero) > 0) {
    cat("Las siguientes variables tienen una varianza cercana o igual a 0:\n")
    cat(names(varianzas_cercanas_a_cero), "\n")
  } else {
    cat("No se encontraron variables con varianza cercana o igual a 0.\n")
  }
}

calcular_varianza(all_data)

```

### Análisis de asimetría

```{r}
 
# Calcular la asimetría de las columnas en all_data
skewness_results <- sapply(all_data, moments::skewness)

# Crear un histograma de los coeficientes de asimetría
hist(skewness_results, breaks = 30, main = "Histograma del Coeficiente de Asimetría",
     xlab = "Coeficiente de Asimetría", ylab = "Frecuencia",
     col = 'green',
     xlim = c(0, 40),  # Establecer límites del eje x
     xaxp = c(0, 40, 10))  # Especificar los extremos y la cantidad de marcas en el eje x

# Calcular la media del coeficiente de asimetría
media_skewness <- mean(skewness_results)

# Agregar la línea vertical para la media
abline(v = media_skewness, col = "red", lwd = 2)

```

La figura muestra un gráfico en cuyo eje X se encuentran los valores del coeficiente de asimetría de las variables, mientras que en el eje Y se representa la cantidad de variables que tienen un coeficiente de asimetría dentro de cada intervalo del histograma.

La mayoría de coeficientes se agrupan cerca del valor 0, lo que sugiere que las distribuciones de las variables son relativamente simétricas. Sin embargo, un pequeño número de genes tienen coeficientes de asimetría extremadamente altos. Estos genes tienen distribuciones altamente sesgadas a la derecha, lo que puede ser debido a los valores altos de expresión en algunas muestras.

### Porcentaje a superar por el modelo

Para considerar útil el modelo, debería presentar un porcentaje de aciertos mayor en la clasificación que al realizarlo por azar. Para comprobarlo, se calcula el porcentaje que se obtendría si se clasificaran todas las muestras como la clase mayoritaria (Tumor en nuestro caso). Si el modelo supera este porcentaje, puede ser tomado en cuenta para futuros estudios.

```{r}
#cogemos las filas del dataset de entrenamiento que se corresponden con las muestras
t_observaciones <- nrow(train_set)
#Agregamos etiqueta "Tumor" al lado de cada muestra
predicciones <- rep(x = "Tumor",  t_observaciones)
#Calculamos el porcentaje de aciertos con respecto al Tipo real de cada muestra
mean(predicciones == train_set$Tipo) * 100
```

## Procesamiento

### Centrado, escalado y normalización de los datos

Se comienza el procesado de los datos, donde se aplica un escalado, centrado y transformación Yeo-Johnson para acercar los datos a una distribución normal.

```{r}
all_data = predict(preProcess(all_data,method = c("center", "scale", "YeoJohnson")),all_data) 
```

## Visualización de datos tras procesamiento

### Coeficiente de asimetría (postprocesado)

Se vuelve a visualizar el coeficiente de asimetría para probar que una vez aplicada la función YeoJohnson, la distribución de los datos ha cambiado y presenta una más parecida a la distribución normal.

```{r}
skewness_results <- sapply(all_data, moments::skewness)

# Crear un histograma de los coeficientes de asimetría
hist(skewness_results, breaks = 30, main = "Histograma del Coeficiente de Asimetría",
     xlab = "Coeficiente de Asimetría", ylab = "Frecuencia",
     border = 'green',
     xlim = c(0, 40),  # Establecer límites del eje x
     xaxp = c(-10, 40, 10))  # Especificar los extremos y la cantidad de marcas en el eje x

# Calcular la media del coeficiente de asimetría
media_skewness <- mean(skewness_results)

# Agregar la línea vertical para la media
abline(v = media_skewness, col = "red", lwd = 2)

```

Al procesar los datos, se observa un cambio en el coeficiente de asimetría. En esta gráfica, la mayoría de los coeficientes estan distribuidos alrededor del 0, lo que indica que la distribución no presenta un sesgo significativo hacia ningún lado.

Esta simetría es resultado de la transformación de los datos para acercarlos a una distribución normal. En una distribución gaussiana, los datos se distribuyen de manera uniforme alrededor de su media, reflejando un balance en ambos lados de la curva, sin inclinaciones predominantes.

La normalización de los datos es fundamental para los algoritmos de Machine Learning, ya que muchos de ellos esperan que los datos sigan una distribución normal.

### Dimensionalidad

A continuación, se añade la columna "Tipo" a all_data, que había sido eliminada anteriormente ya que los procedimientos anteriores no permitían una columna de tipo factor.

```{r}
all_data$Tipo=tmp$Tipo

train_set = all_data[1:nrow(train_set),]

test_set = all_data[(nrow(train_set)+1):(nrow(train_set)+nrow(test_set)),]
```

Los siguientes algoritmos permiten una representación en una dimensión más simple de los datos, lo que permitirá hacernos una idea más visual de cómo las muestras están distribuidas en función de la expresión de cada gen.

#### Algoritmo t-SNE

```{r}
set.seed(94512)   
tsne <- Rtsne(all_data[,colnames(all_data)!='Tipo'], dims = 2, perplexity=15, verbose=TRUE, max_iter = 500)

tsne.df = as.data.frame(tsne$Y)
rownames(tsne.df) = rownames(all_data)
colnames(tsne.df) = c('tsne.1', 'tsne.2')

tsne.df$Tipo = all_data$Tipo

ggplot(tsne.df, aes(x=tsne.1, y=tsne.2, color=Tipo))+
  geom_point()+
  theme_bw()
```

En esta representación se puede observar cómo las muestras se distribuyen a lo largo del espacio, revelando 3 grupos distintos: uno compuesto por muestras de tipo "Normal", otro por muestras de tipo "Tumor", y un tercer grupo donde las muestras de ambos tipos aparecen mezcladas.

La población compuesta exclusivamente por muestras clasificadas como "Normal" sugiere que estas muestras poseen características distintivas que las separan claramente de las muestras clasificadas como "Tumor".

Por otro lado, la población mixta, que muestra una mezcla de muestras clasificadas como "Normal" y "Tumor", sugiere cierto grado de solapamiento entre estas dos clases. Esto podría reflejar la variabilidad biológica o la heterogeneidad dentro de las muestras tumorales, donde algunas muestras comparten características similares a las muestras normales.

La presencia de múltiples poblaciones y el cierto grado de solapamiento entre ellas indica una estructura de datos compleja. Esta complejidad podría estar relacionada con la diversidad biológica de las muestras, la variabilidad en la expresión génica entre las muestras o con la presencia de diferentes subtipos de tumores.

Si aumentamos el número de iteraciones, el resultado representado será más preciso, aunque como podemos ver no hay mucha diferencia significativa.

```{r}
set.seed(94512)   
tsne <- Rtsne(all_data[,colnames(all_data)!='Tipo'], dims = 2, perplexity=15, verbose=TRUE, max_iter = 1000)

tsne.df = as.data.frame(tsne$Y)
rownames(tsne.df) = rownames(all_data)
colnames(tsne.df) = c('tsne.1', 'tsne.2')

tsne.df$Tipo = all_data$Tipo

ggplot(tsne.df, aes(x=tsne.1, y=tsne.2, color=Tipo))+
  geom_point()+
  theme_bw()
```

#### Algoritmo UMAP

UMAP es otro algoritmo utilizado para la exploración y visualización de grandes conjuntos de datos, preservando las relaciones entre las muestras en el proceso de reducción de dimensionalidad, por lo que si las muestras están cercanas en el espacio original, también lo estarán en el reducido.

```{r}
# Calcular UMAP
umap_result <- umap(all_data[, colnames(all_data) != 'Tipo'], n_neighbors = 15, n_components = 2)

# Crear un dataframe con los resultados de UMAP
umap_df <- as.data.frame(umap_result$layout)
colnames(umap_df) <- c('umap.1', 'umap.2')

# Agregar la columna de Tipo
umap_df$Tipo <- all_data$Tipo

# Crear el gráfico de dispersión con relación de aspecto ajustada
ggplot(umap_df, aes(x = umap.1, y = umap.2, color = Tipo)) +
  geom_point() +
  theme_bw() +
  coord_fixed(ratio = 3)  # Ajustar la relación de aspecto


```

Como se puede observar, muestra unos resultados parecidos a los de t-SNE. Hay tres grupos representados, uno correspondiente a muestras tumorales, otro a muestras normales y, por último, uno donde se agrupan muestras procedentes de ambos tipos.

# Algoritmos de aprendizaje

Ahora se comienza con el entrenamiento de los algoritmos para la clasificación.

## Algoritmos lineales

### LDA

```{r}
set.seed(7)
fit.lda <- train(Tipo~., data=train_set, method="lda", metric="Accuracy", trControl=trainControl(method = "cv", number = 10))
fit.lda
```

## Algoritmos no lineales

### CART

```{r}
set.seed(7)
fit.cart <- train(Tipo~., data=train_set, method="rpart", metric="Accuracy", trControl=trainControl(method = "cv", number = 10), tuneLength = 10)

fit.cart
```

Representación de la evolución de la precisión en función del parámetro de complejidad.

```{r}
ggplot(fit.cart)
```

```{r}
fit.cart$finalModel
```

```{r}
rpart.plot(fit.cart$finalModel)
```

El árbol muestra que se han evaluado un total de 9 condiciones para realizar la clasificación final.

### KNN

```{r}
# kNN
set.seed(7)
fit.knn <- train(Tipo~., data=train_set, method="knn", metric="Accuracy", trControl=trainControl(method = "cv", number = 10), tuneLength = 10)
fit.knn
```

Se puede representar cómo evoluciona la precisión en función del número de vecinos.

```{r}
plot(fit.knn)
```

Esta representación es en forma escalón

```{r}
plot(fit.knn, print.thres = 0.5, type="S")

```

### SVM

```{r}
# SVM
set.seed(7)
fit.svm <- train(Tipo~., data=train_set, method="svmRadial", metric="Accuracy", trControl=trainControl(method = "cv", number = 10), tuneLength=2)
fit.svm
```

```{r}
fit.svm$bestTune
```

Representación de la precisión en función del coste establecido.

```{r}
plot(fit.svm)
```

### Random Forest

```{r}
# Random Forest
set.seed(7)
fit.rf <- train(Tipo~., data=train_set, method="rf", metric="Accuracy", trControl=trainControl(method = "cv", number = 10))
fit.rf

(fit.rf$results)
```

### Redes neuronales

```{r}
control <- trainControl(method="cv", number=10)

grid <- expand.grid(size = c(1,2), decay = c(0.95, 0.09))

set.seed(7)
fit.nnet <- train(Tipo ~ ., data=train_set, method="nnet", 
                  trControl=trainControl(method = "cv", number = 10), tuneGrid=grid, linout=FALSE, trace=FALSE, MaxNWts=3000, maxit=200)

fit.nnet
```

### XGBoost

```{r}
metric = "Accuracy"
control <- trainControl(method = "cv", number = 10)
```

```{r}
#XGBoosting

set.seed(7)

fit.xgb <- train(Tipo ~ ., data = train_set, method = "xgbTree", metric=metric, trControl = control, tuneLength = 3, verbosity = 0)
  
fit.xgb
```

## Resumen del resultado del entrenamiento de los modelos

```{r}
results <- resamples(list(lda=fit.lda, cart=fit.cart, knn=fit.knn, svm=fit.svm, rf=fit.rf, xgb=fit.xgb, nnet=fit.nnet))
summary(results)
```

```{r}
dotplot(results)
```

Los modelos con mejor rendimiento son los de XGBoost y SVM, que serán los elegidos para continuar con la validación y la importancia de las variables.

## Resultados con el conjunto de test

A continuación, se utiliza la función predict() de caret para predecir nuevos datos. Esta función utiliza el modelo final, que es el que mejor rendimiento ofrece según los parámetros escogidos por cada algoritmo.

```{r}
set.seed(7)
predictionsXGB <- predict(fit.xgb,test_set)
predictionsSVM <- predict(fit.svm,test_set)

```

```{r}
confusion_matrixXGB <-confusionMatrix(predictionsXGB, test_set$Tipo)
confusion_matrixSVM <-confusionMatrix(predictionsSVM, test_set$Tipo)

print(confusion_matrixXGB)
print(confusion_matrixSVM)

```

![**Curvas ROC de los modelos XGBoost y SVM obtenidas mediante DALEX.** (código comentado más adelante)](images/CurvaROC%20modelos.PNG)

Se puede observar que ambos modelos muestran curvas ROC similares y casi perfectas.

# Explicabilidad de los modelos

## Importancia de las variables de SVM

Para identificar las variables a las que los modelos otorgan mayor importancia en la clasificación de las muestras, se utiliazrá la función varImp() de caret.

```{r}
variablesSVM<- varImp(fit.svm, scale = FALSE)
plot(variablesSVM, top = 20)
```

Como se puede observar, los resultados aparecen con el Id del gen. Para reconocer mejor el gen, se tiene que modificar el código y hacer que se muestren los símbolos.

```{r}
#con varImp() se calcula la importancia que el algoritmo ha asignado a cada variable
imp_svm <- varImp(fit.svm)

#se crea una columna que contenga los Entrez_Gene_Id de los genes sacados a partir de los nombres de las filas
imp_svm$importance <- imp_svm$importance %>% mutate(gene_name = sapply(strsplit(rownames(imp_svm$importance), '_'), `[`, 2))
#se cambia el tipo de esa columna a numérico
imp_svm$importance$gene_name <- as.numeric(imp_svm$importance$gene_name) 
#se hace un left_join para conseguir los nombres de los genes relacionados con los Ids
imp_svm$importance <- imp_svm$importance %>% left_join(cancer_genes, by = c("gene_name" = "entrez"))
#se cambia el nombre de las filas por el de los nombres de los genes
rownames(imp_svm$importance) = imp_svm$importance$symbol
#se eliminan las filas añadidas anteriormente para que no interfieran en el plot
imp_svm$importance <- imp_svm$importance[, -c(3, 4, 5, 6, 7, 8)]

plot(imp_svm, top=20)

imp_svm$importance
```

## Importancia de las variables de XGBoost

```{r}
variablesXGB<- varImp(fit.xgb, scale = FALSE)
plot(variablesXGB, top = 20)
```

```{r}
imp_xgb <- varImp(fit.xgb)

imp_xgb$importance <- imp_xgb$importance %>% mutate(gene_id = sapply(strsplit(rownames(imp_xgb$importance), '_'), `[`, 2))

imp_xgb$importance$gene_id <- as.numeric(imp_xgb$importance$gene_id) 

imp_xgb$importance <- imp_xgb$importance %>% left_join(cancer_genes, by = c("gene_id" = "entrez"))

rownames(imp_xgb$importance) = imp_xgb$importance$symbol

imp_xgb$importance$Overall2 = imp_xgb$importance$Overall

imp_xgb$importance <- imp_xgb$importance[, -c(2, 3, 4, 5, 6, 7)]

plot(imp_xgb, top=20)



imp_xgb$importance
```

Al analizar ambos gráficos, se observa que hay genes que aparecen tanto en un modelo como en el otro.

Es el caso de genes como FOXO1, el cual aparece en segundo lugar en ambos gráficos, aunque en el modelo SVM posee una mayor importancia; SIX2, el cual aparece en primer lugar para XGBoost y en quinto lugar para SVM; NOTCH1, apareciendo en el cuarto lugar en el gŕafico de SVM y en séptimo lugar para XGBoost; STAT5B, que aparece en el tercer puesto para SVM y en el sexto para XGBoost. Por ultimo, RSPO3, el cual aparece en lugares inferiores para ambos algoritmos.

Estos genes podrían ser de gran interés para futuras investigaciones.

# Explicabilidad del modelo con DALEX

Este apartado aparece comentado puesto que, a pesar de haber trabajado en ello, se decidió no utilizar los resultados obtenidos de esta librería ya que mostraban ciertas incoherencias. En la memoria se muestran los reultados de algunas gráficas.

<!-- Para el uso de la librería Dalex, nuestra variable tipo factor debe estar binarizada. Para no cambiar el dataset anterior, sobreescribimos los datos en nuevos data frames y los binarizamos. -->

```{r}
 # train_setModelos <- train_set
 # train_setModelos$Tipo <- factor(train_setModelos$Tipo, levels = c("Normal", "Tumor"), labels = c(0, 1))
 # levels(train_setModelos$Tipo)
 # train_setModelos$Tipo <- as.numeric(train_setModelos$Tipo) - 1
 # 
 # test_setModelos <- test_set
 # test_setModelos$Tipo <- factor(test_setModelos$Tipo, levels = c("Normal", "Tumor"), labels = c(0, 1))
 # levels(test_setModelos$Tipo)
 # test_setModelos$Tipo <- as.numeric(test_setModelos$Tipo) -1
 # 
 # cancer_genes2 <- cancer_genes
 # cancer_genes2$entrez <- paste0("g_", cancer_genes2$entrez)
```

<!-- Primero debemos entrenar un modelo con los datos. -->

<!-- El siguiente paso es crear un objeto explain utilizando DALEX. Este explain es un objeto que contiene el modelo, los datos, la variable objetivo y una etiqueta para identificar el modelo. Gracias a este objeto, DALEX es capaz de interpretar y explicar el modelo. -->

```{r}

#MODELO DE XGBOOST
 #set.seed(7)
 #model_xgb <- train(as.factor(Tipo) ~ ., data = train_setModelos, method = "xgbTree", metric="Accuracy", trControl = trainControl(method = "cv", number = 10), tuneLength = 3)
# 
 #exp_xgb <- DALEX::explain(model_xgb, data = train_setModelos[,-706], y = train_setModelos$Tipo, label ="XGBoost", type="classification")
# 
# exp_xgb_updated <- update_data(exp_xgb, data = test_setModelos[, -706], y = test_setModelos$Tipo)
# 
# 
# perf_xgb <- model_performance(exp_xgb_updated)
 #perf_xgb
```

```{r}
#MODELO DE CART
# set.seed(7)
# model_cart <- train(as.factor(Tipo)~ ., data=train_setModelos, method="rpart", metric="Accuracy", trControl= trainControl(method = "cv", number = 10, selectionFunction = "oneSE"), tuneLength=20)
# 
# exp_cart <- DALEX::explain(model_cart, data = train_setModelos[,-706], y = train_setModelos$Tipo, label ="cart", type="classification")
# 
# 
# exp_cart_updated <- update_data(exp_cart, data = test_setModelos[, -706], y = test_setModelos$Tipo)
# 
# 
# perf_cart <- model_performance(exp_cart_updated)
# perf_cart
```

```{r}
#MODELO DE SVM
 #set.seed(7)
 #model_svm <- train(as.factor(Tipo)~ ., data=train_setModelos, method="svmRadial", metric="Accuracy", trControl= trainControl(method = "cv", number = 10), prob.model = TRUE, tuneLength=2)
# 
# exp_svm <- DALEX::explain(model_svm, data = train_setModelos[,-706], y = train_setModelos$Tipo, label ="svm", type="classification")
# 
# exp_svm_updated <- update_data(exp_svm, data = test_setModelos[, -706], y = test_setModelos$Tipo)
# 
# 
# perf_svm <- model_performance(exp_svm_updated)
# perf_svm
```

```{r}
#MODELO DE RANDOM FOREST
# set.seed(7)
# 
# model_rf <- train(as.factor(Tipo)~., data=train_setModelos, method="rf", metric="Accuracy", trControl=trainControl(method = "cv", number = 10), prob.model = TRUE)
# exp_rf <- DALEX::explain(model_rf, data = train_setModelos[,-706], y = train_setModelos$Tipo, label ="rf", type="classification")
# 
# 
# exp_rf_updated <- update_data(exp_rf, data = test_setModelos[, -706], y = test_setModelos$Tipo)
# 
# perf_rf <- model_performance(exp_rf_updated)
# perf_rf
```

```{r}
#MODELO RED NEURONAL
# set.seed(7)
# 
# model_nnet <- train(as.factor(Tipo) ~ ., data=train_setModelos, method="nnet", trControl=trainControl(method="cv", number=10), tuneGrid=expand.grid(size = c(1,2), decay = c(0.95, 0.09)), linout=FALSE, trace=FALSE, MaxNWts=3000, maxit=200)
# 
# exp_nnet <- DALEX::explain(model_nnet, data = train_setModelos[,-706], y = train_setModelos$Tipo, label ="nnet", type="classification")
# 
# 
# exp_nnet_updated <- update_data(exp_nnet, data = test_setModelos[, -706], y = test_setModelos$Tipo)
# 
# perf_nnet <- model_performance(exp_nnet_updated)
# perf_nnet
```

```{r}
#MODELO LDA
# set.seed(7)
# model_lda <- train(as.factor(Tipo)~., data=train_setModelos, method="lda", metric="Accuracy", trControl=trainControl(method = "cv", number = 10))
# exp_lda <- DALEX::explain(model_lda, data = train_setModelos[,-706], y = train_setModelos$Tipo, label ="lda", type="classification")
# 
# exp_lda_updated <- update_data(exp_lda, data = test_setModelos[, -706], y = test_setModelos$Tipo)
# 
# perf_lda <- model_performance(exp_lda_updated)
# perf_lda
```

```{r}
#MODELO KNN
# set.seed(7)
# model_knn <- train(as.factor(Tipo)~., data=train_setModelos, method="knn", metric="Accuracy", trControl=trainControl(method = "cv", number = 10), tuneLength = 10)
# exp_knn <- DALEX::explain(model_knn, data = train_setModelos[,-706], y = train_setModelos$Tipo, label ="knn", type="classification")
# 
# exp_knn_updated <- update_data(exp_knn, data = test_setModelos[, -706], y = test_setModelos$Tipo)
# 
# 
# perf_knn<- model_performance(exp_knn_updated)
# perf_knn
```

Una vez creados los modelos, se pueden representar varias gráficas como pueden ser la del rendimiento de los mismos o las curvas ROC.

```{r}
#Representación del rendimineto de los modelos

# plot(perf_xgb, perf_svm, perf_cart, perf_rf, perf_nnet, perf_knn)

```

```{r}
#Representación de las curvas ROC de los modelos

#plot(perf_xgb, perf_svm,  geom = "roc")

#plot(perf_xgb, perf_svm, perf_cart, perf_rf, perf_nnet, perf_knn,  geom = "roc")

```

```{r}
#Representación boxplot de los modelos

# plot(perf_xgb, perf_svm, perf_cart, perf_rf, perf_nnet, perf_knn, geom = "boxplot")

```

<!-- ## Importancia de las variables -->

Para la importancia de las variables es necesaria ejecutar la función model_parts(). Esta función requiere mucho tiempo para poder ser ejecutada, llegando incluso a 40 minutos según el algoritmo.

```{r}
#Con la función model_parts, DALEX es capaz de calcular la importancia de las variables de los explainers previamente creados

# mp_svm <- model_parts(exp_svm, type = "difference")
# mp_xgb <- model_parts(exp_xgb, type = "difference")
# mp_cart <- model_parts(exp_cart, type = "difference")
# mp_rf <-  model_parts(exp_rf, type = "difference")
# mp_nnet <-  model_parts(exp_nnet, type = "difference")
# mp_lda <- model_parts(exp_lda, type = "difference")
# mp_knn <- model_parts(exp_knn, type = "difference")

```

```{r}
#Representación de las variables del modelo XGBoost

#plot(mp_xgb, show_boxplots = FALSE)
```

```{r}
#Debido a que DALEX realiza iteraciones con permutaciones en las variables para calcular la importancia de las mismas, se pretendía realizar la media de los valores resultantes en cada iteración, de modo que con ellos se pudiesen comparar los genes y ordenarlos de manera descendente para mostrar los 20 primeros

#El resultado fue que gráficas como las de la red neuronal o Random Forest aparecen vacías y, otras carecen de sentido.


# top_variablesFiltradoLDA <- mp_lda %>% filter(variable != "_baseline_")
# 
# 
# top_variablesLDA <- top_variablesFiltradoLDA  %>% group_by(variable) %>% summarize(mean_dropout_loss = mean(dropout_loss, na.rm = TRUE)) %>% arrange(desc(mean_dropout_loss))
# 
# 
# top_variables10LDA  <- top_variablesLDA  %>% head(20)
# 
# # Hacer un join con el dataframe de nombres de genes
# top_variables10LDA  <- top_variables10LDA  %>% left_join(cancer_genes2, by = c("variable" = "entrez"))
# 
# # Graficar
# ggplot(top_variables10LDA , aes(x = reorder(symbol, mean_dropout_loss), y = mean_dropout_loss)) +
#   geom_bar(stat = "identity") +
#   coord_flip() +
#   labs(title = "Importancia de las variables", x = "Gen", y = "Media de Dropout Loss") +
#   theme_minimal()
```

```{r}
# top_variablesFiltradoNNET <- mp_nnet %>% filter(variable != "_baseline_")
# 
# 
# top_variablesNNET<- top_variablesFiltradoNNET %>% group_by(variable) %>% summarize(mean_dropout_loss = mean(dropout_loss, na.rm = TRUE)) %>% arrange(desc(mean_dropout_loss))
# 
# 
# top_variables10NNET <- top_variablesNNET %>% head(20)
# 
# # Hacer un join con el dataframe de nombres de genes
# top_variables10NNET <- top_variables10NNET %>% left_join(cancer_genes2, by = c("variable" = "entrez"))
# 
# # Graficar
# ggplot(top_variables10NNET, aes(x = reorder(symbol, mean_dropout_loss), y = mean_dropout_loss)) +
#   geom_bar(stat = "identity") +
#   coord_flip() +
#   labs(title = "Importancia de las variables", x = "Gen", y = "Media de Dropout Loss") +
#   theme_minimal()
```

```{r}

# top_variablesFiltradoXgb <- mp_xgb %>% filter(variable != "_baseline_")
# 
# 
# top_variablesXgb <- top_variablesFiltradoXgb %>% group_by(variable) %>% summarize(mean_dropout_loss = mean(dropout_loss, na.rm = TRUE)) %>% arrange(desc(mean_dropout_loss))
# 
# 
# top_variables10Xgb <- top_variablesXgb %>% head(20)
# 
# # Hacer un join con el dataframe de nombres de genes
# top_variables10Xgb <- top_variables10Xgb %>% left_join(cancer_genes2, by = c("variable" = "entrez"))
# 
# # Graficar
# ggplot(top_variables10Xgb, aes(x = reorder(symbol, mean_dropout_loss), y = mean_dropout_loss)) + 
#   geom_bar(stat = "identity") + 
#   coord_flip() + 
#   labs(title = "Importancia de las variables", x = "Gen", y = "Media de Dropout Loss") + 
#   theme_minimal()
```

```{r}
# top_variablesFiltradoRf <- mp_rf %>% dplyr::filter(variable != "_baseline_")
# 
# 
# top_variablesRf <- top_variablesFiltradoRf %>% group_by(variable) %>% summarize(mean_dropout_loss = mean(dropout_loss, na.rm = TRUE)) %>% arrange(desc(mean_dropout_loss))
# 
# 
# top_variables10Rf <- top_variablesRf %>% head(20)
# 
# # Hacer un join con el dataframe de nombres de genes
# top_variables10Rf <- top_variables10Rf %>% left_join(cancer_genes2, by = c("variable" = "entrez"))
# 
# # Graficar
# ggplot(top_variables10Rf, aes(x = reorder(symbol, mean_dropout_loss), y = mean_dropout_loss)) + 
#   geom_bar(stat = "identity") + 
#   coord_flip() + 
#   labs(title = "Importancia de las variables", x = "Gen", y = "Media de Dropout Loss") + 
#   theme_minimal()

```

```{r}
# top_variablesFiltrado <- mp_svm %>% filter(variable != "_baseline_")
# 
# 
# top_variables <- top_variablesFiltrado %>% group_by(variable) %>% summarize(mean_dropout_loss = mean(dropout_loss, na.rm = TRUE)) %>% arrange(desc(mean_dropout_loss))
# 
# 
# top_variables10 <- top_variables %>% head(20)
# 
# top_variables10 <- top_variables10 %>% left_join(cancer_genes2, by = c("variable" = "entrez"))
# 
# ggplot(top_variables10, aes(x = reorder(symbol, mean_dropout_loss), y = mean_dropout_loss)) + 
#   geom_bar(stat = "identity") + 
#   coord_flip() + 
#   labs(title = "Importancia de las variables", x = "Variable", y = "Media de Dropout Loss") + 
#   theme_minimal()
```

```{r}
# top_variablesFiltradoCart <- mp_cart %>% filter(variable != "_baseline_")
# 
# 
# top_variablesCart <- top_variablesFiltradoCart %>% group_by(variable) %>% summarize(mean_dropout_loss = mean(dropout_loss, na.rm = TRUE)) %>% arrange(desc(mean_dropout_loss))
# 
# 
# top_variables10Cart <- top_variablesCart %>% head(20)
# 
# top_variables10Cart <- top_variables10Cart %>% left_join(cancer_genes2, by = c("variable" = "entrez"))
# 
# ggplot(top_variables10Cart, aes(x = reorder(symbol, mean_dropout_loss), y = mean_dropout_loss)) + 
#   geom_bar(stat = "identity") + 
#   coord_flip() + 
#   labs(title = "Importancia de las variables", x = "Variable", y = "Media de Dropout Loss") + 
#   theme_minimal()
```
